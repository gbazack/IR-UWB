{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import rarfile\n",
    "import numpy as np\n",
    "from matplotlib import image as mpimg\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a directory named data/\n",
    "dir_path=os.path.join(os.getcwd(),'github_data/')\n",
    "#os.mkdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the file, rename and save it to content/iruwb_data/\n",
    "#For instance: We want to download the file Data part1_1.rar\n",
    "#We rename it datapart1_1.rar and save it to content/iruwb_data\n",
    "#f_path=os.path.join(os.getcwd(),'dataset1_2.rar')\n",
    "\n",
    "!wget -O dataset4_6.rar https://github.com/yangxiuzhu777/IR-UWB-Radar-Signal-Dataset-for-Dense-People-Counting/blob/master/Dataset%20part%204_6.rar?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decompress and extract the files to content/iruwb_data/\n",
    "#rfile=rarfile.RarFile(f_path)\n",
    "#rfile.extractall(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the destination directory\n",
    "#os.chdir(dir_path)\n",
    "#os.getcwd()\n",
    "os.rename('Dataset part 1_2', 'dataset1_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data to np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[]; labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List all the files of \"dataset1_1/0/\" directory\n",
    "listfiles=os.listdir('dataset4_6/15/.')\n",
    "for x in range(len(listfiles)):\n",
    "    labels.append(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(labels)\n",
    "#listfiles=os.listdir('dataset1_3/7/.')\n",
    "#print(os.listdir('dataset1_3/7/.')==listfiles)\n",
    "#len(listfiles)\n",
    "#i=0\n",
    "#for filename in listfiles:\n",
    "#    #filename=os.path.join('dataset1_1/2',filename) #create the path to a file\n",
    "#    print(filename,'\\t\\t',i)\n",
    "#    i+=1\n",
    "#    read_file=open(filename, 'r')                  #open the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract and preprocess the data from each file\n",
    "for filename in listfiles:\n",
    "    filename=os.path.join('dataset4_6/15',filename) #create the path to a file\n",
    "    read_file=open(filename, 'r')                  #open the file\n",
    "    load_file=read_file.readlines()                #load data from the file as string (str)\n",
    "    \n",
    "    #Create an array of size x_sise*y_size to \n",
    "    #This array is named \"data\"\n",
    "    x_size=len(load_file)\n",
    "    y_size=int((len(load_file[0])+1)/10)\n",
    "    data=np.zeros((x_size,y_size))\n",
    "    \n",
    "    #Clean the data and convert them to float\n",
    "    for index in range(len(load_file)):\n",
    "        \n",
    "        #Remove special characters\n",
    "        load_file[index].replace('\\t', ' ')\n",
    "        load_file[index].replace('\\n', '')\n",
    "        f=[]\n",
    "        \n",
    "        #For each row of the data, convert 1280 string of size 10 to float\n",
    "        for i in range(0, len(load_file[index]), 10):\n",
    "            f.append(load_file[index][i:i+10])\n",
    "        data[index]=f\n",
    "    dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dataset).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('standing_dataset', data=np.array(dataset), labels=np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    name=str(i)+'.png'\n",
    "    imagename=os.path.join(imagedir, str(name)\n",
    "    print(imagename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(0, len(dataset),40):    \n",
    "    imagedir=os.mkdir('images'+str(int(index/40)))\n",
    "    \n",
    "    #Display and save each file as an image\n",
    "    for i in range(index, index+39):\n",
    "        name=str(i)+'.png'\n",
    "        imagename=os.path.join(imagedir, name)\n",
    "        plt.imshow(dataset[i])\n",
    "        plt.ylabel('Slow time index')\n",
    "        plt.xlabel('Fast time index')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(imagename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
